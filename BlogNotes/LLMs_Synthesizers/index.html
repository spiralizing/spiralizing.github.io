<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/pure.css"> <link rel=stylesheet  href="/css/side-menu.css"> <style> :root { --content-width: 800px; --content-padding: 5%; } .franklin-content { padding-left: var(--content-padding); max-width: 100%; } @media (min-width: 740px) { .franklin-content { width: var(--content-width); margin-left: 5px; padding-left: 90px; } .header { width: 900px; } } /* Improve accessibility for screen readers */ .sr-only { position: absolute; width: 1px; height: 1px; padding: 0; margin: -1px; overflow: hidden; clip: rect(0, 0, 0, 0); white-space: nowrap; border-width: 0; } </style> <link rel=icon  href="/assets/spiral1.jpg"> <title>LLMs as approximate information synthesizers</title> <meta property="twitter:card" content=summary > <meta property="twitter:creator" content=sethaxen > <meta property="twitter:title" content="LLMs as approximate information synthesizers"> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a class="pure-menu-heading " ><a href="/" class=pure-menu-heading >Home</a> <ul class="pure-menu-list "><a href="/Research/" class=pure-menu-subheading >Research Projects</a> <li class="pure-menu-item "><a href="/MusicEvo/" class=pure-menu-link >Music Evolution</a> <li class="pure-menu-item "><a href="/Cancer/" class=pure-menu-link >Breast Cancer</a> <li class="pure-menu-item "><a href="/PhysChem/" class=pure-menu-link >Physical Chemistry</a> </ul> <ul class="pure-menu-list "><a href="/DataScience/" class=pure-menu-subheading >Data Science</a> <li class="pure-menu-item "><a href="/DSEntries/CenterOfEffect/" class=pure-menu-link >What key is Hey Joe in</a> <li class="pure-menu-item "><a href="/DSEntries/SentimentSongs1/" class=pure-menu-link >Sentiment in songs</a> <li class="pure-menu-item "><a href="/DSEntries/SemanticGraph/" class=pure-menu-link >Semantic Graph </a> <li class="pure-menu-item "><a href="/DSEntries/StyleTransfer/" class=pure-menu-link >Style Transfer</a> <li class="pure-menu-item "><a href="/DSEntries/LLMs/" class=pure-menu-link >Exploring LLMs</a> <li class="pure-menu-item "><a href="/DSEntries/WineQuality/" class=pure-menu-link >Wine Quality </a> </ul> <ul class="pure-menu-list "><a href="/Blog/" class=pure-menu-subheading >Personal Notes</a> <li class="pure-menu-item pure-menu-selected"><a href="/BlogNotes/LLMs_Synthesizers/" class=pure-menu-link >LLMs as Synthesizers</a> </div> </div> <div id=main > <div class=header > <h1>LLMs as approximate information synthesizers</h1> <h2> Complex Systems and Computational Methods in Interdisciplinary Research </h2> </div> <div class=franklin-content > <blockquote> <p><em>A simple -<em>and short</em>- framework for effectively integrating LLMs into academic and professional workflows</em></p> </blockquote> <p>We all know by now that LLMs have been the most transformational tool that no one asked for—in the sense that there was never a clear use case or guidance when the technology was released to the general public. Since then, like many others, I have been exploring these tools, playing with them, reading about them, and trying to understand them. A few weeks ago, after I felt confident enough, I started sharing with my colleagues how I use &quot;AI&quot; in my work. These conversations motivated me to write this short post about the subject, as I believe I&#39;ve found an effective way to explain how I integrate Large Language Models into my general workflow.</p> <p>When a new tool is introduced, it comes with established terminology. In the case of Large Language Models, most people refer to them as &quot;Artificial Intelligence,&quot; and this term has hyped the field so much that it&#39;s now used everywhere—as if adding the term immediately unlocks some kind of <strong>magical feature</strong>. The problem with this approach of using &quot;magical,&quot; &quot;esoteric,&quot; or &quot;sensationalist&quot; terms to explain scientific or mathematical concepts is that they aren&#39;t practical in the real world. So I&#39;m going to use a different term to refer to Large Language Models &#40;beyond just &quot;LLMs&quot;&#41; that can also help explain how I integrate them into my work.</p> <h2 id=llms_are_synthesizers ><a href="#llms_are_synthesizers" class=header-anchor >LLMs are Synthesizers</a></h2> <blockquote> <p><em>Just as sound synthesizers transform elements of sound into useful and coherent outputs such as &quot;music&quot; through the lens of an artist, LLMs efficiently transform elements of information into useful information formats and shapes through the lens of a professional expert.</em></p> </blockquote> <p>The analogy that has been extremely useful for me in finding good use-cases for Large Language Models in my workflow is to approach them as &quot;Approximate Information Synthesizers.&quot; <strong>Just as sound synthesizers transform elements of sound into useful and coherent outputs such as <em>music</em> through the lens of an artist, LLMs efficiently transform elements of information into useful information formats and shapes through the lens of a professional expert.</strong></p> <p>Other way of looking at LLMs is as <em>re-shaping machines</em> that transform <strong>information objects</strong> from an initial state to a final one through their learned representations—the patterns capturing statistical dependencies between tokens. It is safe to imagine LLMs as re-shaping machines since that&#39;s a reasonable description to what they do to the data that its fed to them. And I will use the term &quot;Synthesizers&quot; because I think it describes better than &quot;re-shaping&quot; the process that goes inside the LLM.</p> <p>These Information Synthesizers are &quot;approximate&quot; because of their stochastic nature. This means that whatever you <strong>want as output</strong> from the machine, it will return an <strong>approximation of that output</strong>. The quality of the approximated output varies depending on the difficulty for the synthesizer to build the exact shape that the user wants. This last point is one of the most complicated to address, since each LLM has its own learned representations, training dataset, and development methodology.</p> <p>So when I think of Large Language Models and what they do, I usually imagine:</p> <ul> <li><p>An abstract <em>information object</em> with specific <em>shape</em> properties that depend on the nature of the data representing or referring to the <em>information</em></p> <li><p>A <em>universe of shapes</em> encompassing all possible forms the <em>information object</em> can take</p> <li><p><em>Paths</em> connecting different <em>shapes</em> of the same <em>information object</em></p> <li><p>Going from a <em>shape</em> <strong>A</strong> to a <em>shape</em> <strong>B</strong> requires a transformation that can involve translation, reduction, or expansion of the original information object</p> </ul> <p>The <em>shapes</em> of the information object are what the user can synthesize from the toolbox &#40;LLM&#41;, and the amount and quality of <strong>information</strong> depends on the criteria of the user. Having said that, it is important to point out that <strong>we don&#39;t know the actual size of the universe of shapes that an LLM can create, since it depends on the specifics of the LLM &#40;architecture, training data/method, representations learned, etc.&#41;.</strong></p> <p>Some examples of this process of going from <em>shape</em> <strong>A</strong> to <em>shape</em> <strong>B</strong> include:</p> <ul> <li><p>Answering questions: The <em>shape</em> of the information is a question, and we want to <em>transform</em> it into its answer</p> <li><p>Modifying a code function: This transformation requires a reduction or expansion of the original information object</p> <li><p>Summarizing or elaborating a piece of text: A transformation that reduces or expands the original information object</p> <li><p>Creating an image or video that fits a text: A format transformation/translation that reshapes the original format of the information &#40;text&#41; into a new one &#40;image or sequence of images&#41;</p> </ul> <p>Some of these examples benefit most from adding contextual information &#40;format examples, guides, documentation&#41;, <strong>as long as the length of your input &#43; context remains within the context length of the Large Language Model</strong>. Sometimes, to get a better approximation, we need to create in-between <em>shapes</em> that can lead to the desired <em>shape</em>.</p> <p>If the <em>shape</em> the user wants to create has a high error rate or is too far from the desired outcome, it means the LLM can&#39;t effectively synthesize that type of <em>shape</em>. In such cases, extra steps like fine-tuning or in-context examples &#40;prompt design&#41; might help narrow the gap between the current output and the desired result.</p> <p>At the end of the day, we need to remember that these synthesizers are stochastic by nature, so we don&#39;t have full control over their functionality. However, we can steer them and enhance their utility through a well-designed AI-control framework that includes clear guidelines, feedback mechanisms, and evaluation metrics.</p> <div class=container > <img class=center  src="/assets/llm_synthesizer_1b.png" width=500  height=350 > <blockquote> <cite> Framework diagram example. Using an LLM to go from shape A to shape B. When context is used the approximate output (B') that the LLM generates requires less work for the user to refine it compared with the path without context (B'').</cite></blockquote> </div> <h2 id=shapes_can_be_found_or_created_with_the_llms_building_blocks ><a href="#shapes_can_be_found_or_created_with_the_llms_building_blocks" class=header-anchor >Shapes can be found or created with the LLM&#39;s building blocks</a></h2> <p>The &quot;building blocks&quot; or learned representations of LLMs can <em>be accessed</em> indirectly by prompting the LLM. However, since there is no definitive guidance on how to use them effectively in specific use-case scenarios, this is something that the user will need to <em>discover</em> on their own. This makes the process less independent &#40;not fully automated&#41; but more accurate and safer through AI-control and Human-AI collaboration.</p> <p>Here is the workflow I have been using with this framework:</p> <ol> <li><p>Define a starting and an ending shape</p> <ul> <li><p>Think of an activity you need to do and identify starting points</p> <li><p>Define both shapes as detailed as possible; if something is difficult to define, imagine that shape and write down its detailed features</p> </ul> <li><p>Define sufficient intermediate <em>shapes</em> that <strong>you know how to build on your own</strong> &#40;without an LLM&#41;</p> <ul> <li><p>These shapes don&#39;t need to be as detailed, since they won&#39;t be the final output</p> <li><p>Document each step thoroughly so the process can be semi-reproducible</p> </ul> <li><p>Use the LLM to synthesize intermediate shapes and guide it to the final one</p> <ul> <li><p>Depending on the nature of the shapes, additional user modifications may be needed between steps</p> </ul> </ol> <p>This framework can be implemented in different ways, depending on the <em>shapes</em> you are working with. You can perform iterations with the LLM for refinement, or edit the <em>shapes</em> yourself to better fit your implementation.</p> <div class=container > <img class=center  src="/assets/llm_synthesizer_2b.png" width=500  height=350 > <blockquote> <cite> An example of a workflow using this framework. LLMs can be used to create different in-between steps of approximate shapes, with refinement by the user if needed, in an iterative fashion before getting the final desired shape.</cite></blockquote> </div> <h2 id=use-case_examples_in_my_work ><a href="#use-case_examples_in_my_work" class=header-anchor >Use-case examples in my work</a></h2> <p>My work is interdisciplinary and requires extensive data processing and management, experimental design, hypothesis testing, and other scientific methods in my research and teaching. Integrating LLMs in my workflow has been extremely useful to:</p> <ul> <li><p>Create simple images or mermaid diagrams for classroom presentations</p> <li><p>Write code as an auto-complete assistant</p> <li><p>Edit my writing for clarity &#40;I do this at sentence or short paragraph level, as other approaches are not useful for me&#41;</p> <li><p>Create LaTeX/JSON/Markdown templates for my research and personal notes</p> </ul> <p>Specific examples include:</p> <ul> <li><p>Modifying plotting functions: LLMs excel at modifying long or complicated plotting functions quickly. This is a simple synthesis that requires the source code and either a specific example of what you want or details of what you wish to modify.</p> <li><p>Creating new functions for code. Whenever I want to integrate code in my work, I:</p> <ol> <li><p>Create a first <em>shape</em> that outlines the steps for the task the code needs to perform</p> <li><p>Synthesize a second <em>shape</em> that includes an algorithm following the steps of the first <em>shape</em></p> <li><p>Synthesize a third <em>shape</em> containing pseudo-code that implements the synthesized algorithm</p> <li><p>Synthesize a final approximate <em>shape</em> containing the code in my preferred programming language</p> </ol> </ul> <p>This framework and workflow is transferable to other disciplines and allows users to maintain more control over the process. It enables them to incorporate their own expertise, adding that &quot;human&quot; perspective that brings genuine value to the final product.</p> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Alfredo González-Espinoza. Last modified: May 09, 2025. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> <script src="/libs/pure/ui.min.js"></script> <script src="/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>