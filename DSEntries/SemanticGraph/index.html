<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/pure.css"> <link rel=stylesheet  href="/css/side-menu.css"> <style> .franklin-content{padding-left:10%;} @media (min-width: 940px) { .franklin-content {width: 640px; margin-left: 0px; padding-left: 80px;} .header {width: 700px;} } </style> <link rel=icon  href="/assets/spiral1.jpg"> <title>Building a semantic network</title> <meta property="twitter:card" content=summary > <meta property="twitter:creator" content=sethaxen > <meta property="twitter:title" content="Building a semantic network"> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a class="pure-menu-heading " ><a href="/" class=pure-menu-heading >Home</a> <ul class="pure-menu-list "><a href="/Research/" class=pure-menu-subheading >Research Projects</a> <li class="pure-menu-item "><a href="/MusicEvo/" class=pure-menu-link >Music Evolution</a> <li class="pure-menu-item "><a href="/Cancer/" class=pure-menu-link >Breast Cancer</a> <li class="pure-menu-item "><a href="/PhysChem/" class=pure-menu-link >Physical Chemistry</a> </ul> <ul class="pure-menu-list "><a href="/DataScience/" class=pure-menu-subheading >Data Science</a> <li class="pure-menu-item "><a href="/DSEntries/CenterOfEffect/" class=pure-menu-link >What key is Hey Joe in</a> <li class="pure-menu-item "><a href="/DSEntries/SentimentSongs1/" class=pure-menu-link >Sentiment in songs</a> <li class="pure-menu-item pure-menu-selected"><a href="/DSEntries/SemanticGraph/" class=pure-menu-link >Semantic Graph </a> <li class="pure-menu-item "><a href="/DSEntries/StyleTransfer/" class=pure-menu-link >Style Transfer</a> <li class="pure-menu-item "><a href="/DSEntries/LLMs/" class=pure-menu-link >Exploring LLMs</a> <li class="pure-menu-item "><a href="/DSEntries/WineQuality/" class=pure-menu-link >Wine Quality </a> </ul> </div> </div> <div id=main > <div class=header > <h1>Building a semantic network</h1> <h2> -| Data Science | Complex Systems | Scientific Research | </h2> </div> <div class=franklin-content > <p>A <strong>semantic network</strong>, sometimes referred as <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> is a graph <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=script >G</mi><mo stretchy=false >(</mo><mi>v</mi><mo separator=true >,</mo><mi>e</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">\mathcal{G}(v,e)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.0593em;">G</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal">e</span><span class=mclose >)</span></span></span></span> where the vertices &#40;or nodes&#41; represent concepts, entities, events, etc. and the edges represent a relationship between the concepts. This relationship is said to be <strong>semantic</strong> because the way these networks are built is by preserving spatial relationships between words in written language. One of the simplest ways to build one of these networks is to create edges between words that appear in the same sentence or paragraph, with the assumption that these words are related somehow. </p> <p>Here we are going to build a semantic network from <a href="https://www.cnn.com/">Cable News Network &#40;CNN&#41;</a> articles that I downloaded from a <a href="https://www.kaggle.com/datasets/hadasu92/cnn-articles-after-basic-cleaning">Kaggle dataset</a>.</p> <p>Let&#39;s do some imports first</p> <pre><code class="python hljs"><span class=hljs-comment >#dataframes and arrays</span>
<span class=hljs-keyword >import</span> pandas <span class=hljs-keyword >as</span> pd
<span class=hljs-keyword >import</span> numpy <span class=hljs-keyword >as</span> np
<span class=hljs-comment >#plotting</span>
<span class=hljs-keyword >import</span> seaborn <span class=hljs-keyword >as</span> sns
<span class=hljs-keyword >import</span> matplotlib.pyplot <span class=hljs-keyword >as</span> plt
<span class=hljs-keyword >from</span> IPython <span class=hljs-keyword >import</span> display
display.set_matplotlib_formats(<span class=hljs-string >&#x27;svg&#x27;</span>)</code></pre> <p>We load the <code>.csv</code> file as a data frame and drop the NaNs that might be in it:</p> <pre><code class="python hljs">df_cnn = pd.read_csv(<span class=hljs-string >&#x27;Data/CNN_Articles/CNN_Articels_clean.csv&#x27;</span>)
<span class=hljs-comment >#remove nans</span>
df_cnn.dropna(inplace=<span class=hljs-literal >True</span>)</code></pre> <p>now let&#39;s explore a bit of the dataset and its statistics, we look at the columns to see what information is contained in the data frame</p> <pre><code class="python hljs">df_cnn.columns</code></pre>
<pre><code class="plaintext hljs">Index([&#x27;Index&#x27;, &#x27;Author&#x27;, &#x27;Date published&#x27;, &#x27;Category&#x27;, &#x27;Section&#x27;, &#x27;Url&#x27;,
       &#x27;Headline&#x27;, &#x27;Description&#x27;, &#x27;Keywords&#x27;, &#x27;Second headline&#x27;,
       &#x27;Article text&#x27;],
      dtype=&#x27;object&#x27;)</code></pre>
<p>looks like the articles are classified by categories, let&#39;s explore the count for each category</p>
<pre><code class="python hljs">plt.figure(figsize=(<span class=hljs-number >10</span>,<span class=hljs-number >4</span>))
sns.countplot(df_cnn[<span class=hljs-string >&#x27;Category&#x27;</span>])</code></pre>
<p>
<div class=container >

    <img class=center  src="/assets/cnn_categ.svg" width=500  height=350 >

</div>
 we can see that the number of articles is not uniformly distributed across categories, this could add some bias to our analysis so we will need to make a uniform <em>sample</em> of articles to avoid this. We will catch up on that later, for now let&#39;s see what text can we use to extract the information we need to build our semantic network.</p>
<p>The data frame has <code>Headline</code>, <code>Description</code> and <code>Article text</code> as our potential candidates to extract the information, let&#39;s explore the length -number of words- for each </p>
<pre><code class="python hljs"><span class=hljs-comment >#getting the lengths</span>
art_lenghts = [df_cnn[<span class=hljs-string >&#x27;Article text&#x27;</span>].apply(<span class=hljs-keyword >lambda</span> text: <span class=hljs-built_in >len</span>(text.split(<span class=hljs-string >&#x27; &#x27;</span>))) ,
    df_cnn[<span class=hljs-string >&#x27;Headline&#x27;</span>].apply(<span class=hljs-keyword >lambda</span> text: <span class=hljs-built_in >len</span>(text.split(<span class=hljs-string >&#x27; &#x27;</span>))) ,
    df_cnn[<span class=hljs-string >&#x27;Description&#x27;</span>].apply(<span class=hljs-keyword >lambda</span> text: <span class=hljs-built_in >len</span>(text.split(<span class=hljs-string >&#x27; &#x27;</span>)))
    ]

fig, ax = plt.subplots(<span class=hljs-number >1</span>,<span class=hljs-number >3</span>, figsize=(<span class=hljs-number >16</span>,<span class=hljs-number >4</span>))

ax[<span class=hljs-number >0</span>].hist(art_lenghts[<span class=hljs-number >0</span>])
ax[<span class=hljs-number >0</span>].set_title(<span class=hljs-string >f&#x27;Full text (median <span class=hljs-subst >{np.median(art_lenghts[<span class=hljs-number >0</span>]):<span class=hljs-number >.0</span>f}</span>) &#x27;</span>)
ax[<span class=hljs-number >0</span>].set_xlabel(<span class=hljs-string >&#x27;# words&#x27;</span>)
ax[<span class=hljs-number >0</span>].set_ylabel(<span class=hljs-string >&#x27;Count&#x27;</span>)

ax[<span class=hljs-number >1</span>].hist(art_lenghts[<span class=hljs-number >1</span>])
ax[<span class=hljs-number >1</span>].set_title(<span class=hljs-string >f&#x27;Headline (median <span class=hljs-subst >{np.median(art_lenghts[<span class=hljs-number >1</span>]):<span class=hljs-number >.0</span>f}</span>) &#x27;</span>)
ax[<span class=hljs-number >1</span>].set_xlabel(<span class=hljs-string >&#x27;# words&#x27;</span>)
ax[<span class=hljs-number >1</span>].set_ylabel(<span class=hljs-string >&#x27;Count&#x27;</span>)

ax[<span class=hljs-number >2</span>].hist(art_lenghts[<span class=hljs-number >2</span>])
ax[<span class=hljs-number >2</span>].set_title(<span class=hljs-string >f&#x27;Description (median <span class=hljs-subst >{np.median(art_lenghts[<span class=hljs-number >2</span>]):<span class=hljs-number >.0</span>f}</span>) &#x27;</span>)
ax[<span class=hljs-number >2</span>].set_xlabel(<span class=hljs-string >&#x27;# words&#x27;</span>)
ax[<span class=hljs-number >2</span>].set_ylabel(<span class=hljs-string >&#x27;Count&#x27;</span>)</code></pre>
<p>
<div class=container >

    <img class=center  src="/assets/semnet_distro.svg" width=500  height=250 >

</div>
 for simplicity and trying to avoid any other biases that could be introduced by the data, we are going to use the <code>Description</code> that has a median of 26 words. </p>
<p>Now we focus on the categories we are going to use, since <code>travel</code>, <code>vr</code> and <code>style</code> seem to have few articles, we are going to ignore those categories</p>
<pre><code class="python hljs"><span class=hljs-comment >#categories to use</span>
use_cat = df_cnn[<span class=hljs-string >&#x27;Category&#x27;</span>].unique()[:<span class=hljs-number >6</span>]
<span class=hljs-built_in >print</span>(use_cat)</code></pre>
<pre><code class="plaintext hljs">[&#x27;news&#x27; &#x27;business&#x27; &#x27;health&#x27; &#x27;entertainment&#x27; &#x27;sport&#x27; &#x27;politics&#x27;]</code></pre>
<p>for each category we get a sample of <code>n_articles &#61; 400</code>, this number is arbitrary and is close to the number of articles that the category <code>entertainment</code> has</p>
<pre><code class="python hljs">new_df = pd.DataFrame(columns=df_cnn.columns)
n_articles = <span class=hljs-number >400</span>
<span class=hljs-keyword >for</span> cat <span class=hljs-keyword >in</span> use_cat:
    <span class=hljs-comment >#temporal slice of dataframe</span>
    tmp_df = df_cnn[df_cnn[<span class=hljs-string >&#x27;Category&#x27;</span>] == cat].copy(deep=<span class=hljs-literal >False</span>)
    <span class=hljs-comment >#random choice N articles</span>
    selec_art = np.random.choice(<span class=hljs-built_in >range</span>(tmp_df.shape[<span class=hljs-number >0</span>]), n_articles)
    <span class=hljs-comment >#appending the new dataframe ignoring the index so the new dataframe will have new indexes</span>
    new_df = pd.concat([new_df, tmp_df.iloc[selec_art]], ignore_index=<span class=hljs-literal >True</span>)</code></pre>
<p>now that we have stored the articles we are going to work with in a new data frame <code>new_df</code> we can load a <strong>language model</strong> from the <a href="https://spacy.io/">spaCy</a> library</p>
<pre><code class="python hljs"><span class=hljs-keyword >import</span> spacy
<span class=hljs-comment >#loading the small version of the  model for the english language</span>
nlp = spacy.load(<span class=hljs-string >&#x27;en_core_web_sm&#x27;</span>)</code></pre>
<p>this model has already been prepared to <a href="https://spacy.io/usage/linguistic-features">identify features</a> for the English language &#40;and some other languages too&#41; and comes with tools that helps us analyze texts, in our case we are going to use its <strong>named entity recognition</strong> tool which will recognize and tag entities for a given text.</p>
<p>Let&#39;s try the entity recognition feature from one of the descriptions in the new data frame we made with the sampled articles, first we pass the text through the model</p>
<pre><code class="python hljs"><span class=hljs-comment >#passing one description to our nlp model</span>
des = nlp(new_df[<span class=hljs-string >&#x27;Description&#x27;</span>][<span class=hljs-number >32</span>])
<span class=hljs-comment >#print the original text</span>
<span class=hljs-built_in >print</span>(des.text)</code></pre>
<pre><code class="plaintext hljs">A Monday attack on a Fox News crew reporting near the Ukrainian capital of Kyiv left two of the network&#x27;s journalists dead and its correspondent severely injured, the channel said on Tuesday.</code></pre>
<p>now we import <code>displacy</code> to output a <em>fancy</em> tagging of named entities</p>
<pre><code class="python hljs"><span class=hljs-keyword >from</span> spacy <span class=hljs-keyword >import</span> displacy 

<span class=hljs-comment >#displaying entities of the text</span>
displacy.render(des, style=<span class=hljs-string >&#x27;ent&#x27;</span>)</code></pre>
<p>
<div class=entities  style="line-height: 2.5; direction: ltr">A 
    <mark class=entity  style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
        Monday
        <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
    </mark>
    attack on a 
    <mark class=entity  style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
        Fox News
        <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
    </mark>
    crew reporting near the 
    <mark class=entity  style="background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
        Ukrainian
        <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">NORP</span>
    </mark>
    capital of 
    <mark class=entity  style="background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
        Kyiv
        <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">GPE</span>
    </mark>
    left 
    <mark class=entity  style="background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
        two
        <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">CARDINAL</span>
    </mark>
    of the network\'s journalists dead and its correspondent severely injured, the channel said on 
    <mark class=entity  style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
        Tuesday
        <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
    </mark>.
</div>
 </p>
<p>as we can see, the named entities that the model recognizes have different types and spacy already assigns the type to each identity, if we want to extract this entities we can do it by accessing <code>des.ents</code> from our processed text <code>des</code>.</p>
<p>The fact that named entities are also numbers and dates could add noise to our network so we need to get rid of that type of entities, we can inspect what type of entities our model recognizes by doing </p>
<pre><code class="python hljs">nlp.get_pipe(<span class=hljs-string >&quot;ner&quot;</span>).labels</code></pre>
<pre><code class="plaintext hljs">(&#x27;CARDINAL&#x27;,
 &#x27;DATE&#x27;,
 &#x27;EVENT&#x27;,
 &#x27;FAC&#x27;,
 &#x27;GPE&#x27;,
 &#x27;LANGUAGE&#x27;,
 &#x27;LAW&#x27;,
 &#x27;LOC&#x27;,
 &#x27;MONEY&#x27;,
 &#x27;NORP&#x27;,
 &#x27;ORDINAL&#x27;,
 &#x27;ORG&#x27;,
 &#x27;PERCENT&#x27;,
 &#x27;PERSON&#x27;,
 &#x27;PRODUCT&#x27;,
 &#x27;QUANTITY&#x27;,
 &#x27;TIME&#x27;,
 &#x27;WORK_OF_ART&#x27;)</code></pre>
<p>now we can select what type of entities we are interested in</p>
<pre><code class="python hljs">ent_type = [<span class=hljs-string >&#x27;PERSON&#x27;</span>, <span class=hljs-string >&#x27;NORP&#x27;</span>, <span class=hljs-string >&#x27;FAC&#x27;</span>, <span class=hljs-string >&#x27;ORG&#x27;</span>, <span class=hljs-string >&#x27;GPE&#x27;</span>, <span class=hljs-string >&#x27;LOC&#x27;</span>, <span class=hljs-string >&#x27;PRODUCT&#x27;</span>, <span class=hljs-string >&#x27;EVENT&#x27;</span>,<span class=hljs-string >&#x27;WORK_OF_ART&#x27;</span>, <span class=hljs-string >&#x27;LAW&#x27;</span>, <span class=hljs-string >&#x27;LANGUAGE&#x27;</span>]</code></pre>
<p>and extract them from each of the descriptions in our data <code>new_df</code></p>
<pre><code class="python hljs">art_ents = []
arts_used_ix = []
catego = []
<span class=hljs-keyword >for</span> ix, text <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(new_df[<span class=hljs-string >&#x27;Description&#x27;</span>]):
    des = nlp(text)
    <span class=hljs-keyword >if</span> <span class=hljs-built_in >len</span>(des.ents) &gt; <span class=hljs-number >1</span>: <span class=hljs-comment >#storing only those who have more than 1 entity</span>
        arts_used_ix.append(ix)
        in_ents = []
        <span class=hljs-comment >#saving its category just in case</span>
        catego.append(new_df[<span class=hljs-string >&#x27;Category&#x27;</span>][ix])
        <span class=hljs-keyword >for</span> ent <span class=hljs-keyword >in</span> des.ents:
            <span class=hljs-keyword >if</span> ent.label_ <span class=hljs-keyword >in</span> ent_type:
                in_ents.append(ent.text)
        
        art_ents.append(np.unique(np.array(in_ents)))</code></pre>
<p>and now we can see how many entities we have in total and how many unique entities there are</p>
<pre><code class="python hljs">unique_ents = [element <span class=hljs-keyword >for</span> nestedlist <span class=hljs-keyword >in</span> art_ents <span class=hljs-keyword >for</span> element <span class=hljs-keyword >in</span> nestedlist]
all_ent_len = <span class=hljs-built_in >len</span>(unique_ents)
unique_ents = np.unique(np.array(unique_ents))
vocab_len = <span class=hljs-built_in >len</span>(unique_ents)

<span class=hljs-built_in >print</span>(<span class=hljs-string >f&#x27;There are <span class=hljs-subst >{all_ent_len}</span> named entities with <span class=hljs-subst >{vocab_len}</span> unique ones&#x27;</span>)</code></pre>
<pre><code class="plaintext hljs">There are 4277 named entities with 1857 unique ones</code></pre>
<p>for simplicity, we are going to map the entities to numbers with a dictionary</p>
<pre><code class="python hljs">word2tag = {}
tag2word = {}
<span class=hljs-keyword >for</span> i, ent <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(unique_ents):
    word2tag[ent] = i
    tag2word[i] = ent</code></pre>
<p>now we are going to build our semantic network with the <code>networkx</code> package, first we initialize the graph</p>
<pre><code class="python hljs"><span class=hljs-keyword >import</span> networkx <span class=hljs-keyword >as</span> nx

<span class=hljs-comment >#initializing graph</span>
entG = nx.Graph()</code></pre>
<p>now we iterate over the entities that we saved and use them as nodes to create edges between them if they appear in the same piece of text &#40;description&#41;, we are going to add <strong>weights</strong> to the edges equal to the number of occurrences the two nodes &#40;words&#41; have in the descriptions</p>
<pre><code class="python hljs"><span class=hljs-keyword >for</span> ents <span class=hljs-keyword >in</span> art_ents:
    <span class=hljs-keyword >if</span> <span class=hljs-built_in >len</span>(ents) &gt; <span class=hljs-number >1</span>:
        <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(<span class=hljs-built_in >len</span>(ents)):
            <span class=hljs-keyword >for</span> j <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(i+<span class=hljs-number >1</span>, <span class=hljs-built_in >len</span>(ents)):
                <span class=hljs-comment >#getting the labels for the edges</span>
                v1 = word2tag[ents[i]]
                v2 = word2tag[ents[j]]
                <span class=hljs-comment >#check if the edge exists</span>
                <span class=hljs-keyword >if</span> entG.has_edge(v1, v2):
                    <span class=hljs-comment >#if does exist it adds +1 to its weight</span>
                    entG[v1][v2][<span class=hljs-string >&#x27;weight&#x27;</span>] +=<span class=hljs-number >1</span>
                <span class=hljs-keyword >else</span>:
                    <span class=hljs-comment >#if doesn&#x27;t it creates it</span>
                    entG.add_edge(v1, v2, weight=<span class=hljs-number >1</span>)</code></pre>
<p>and we visualize the resulting network</p>
<pre><code class="python hljs">plot_options = {<span class=hljs-string >&quot;node_size&quot;</span>: <span class=hljs-number >10</span>, <span class=hljs-string >&quot;with_labels&quot;</span>: <span class=hljs-literal >False</span>, <span class=hljs-string >&quot;width&quot;</span>: <span class=hljs-number >0.8</span>}

fig, ax = plt.subplots(figsize=(<span class=hljs-number >15</span>, <span class=hljs-number >15</span>))
ax.axis(<span class=hljs-string >&quot;off&quot;</span>)
nx.draw_networkx(entG, ax=ax,**plot_options)</code></pre>
<p>
<div class=container >

    <img class=center  src="/assets/semnet_fullnet.svg" width=500  height=500 >

</div>
 it looks that there are a lot of articles that have entities disconnected from the main component of the network, we will throw these small, isolated components of our network and use only the largest connected component</p>
<pre><code class="python hljs"><span class=hljs-comment >#finding the largest connected component</span>
large_c = <span class=hljs-built_in >max</span>(nx.connected_components(entG), key=<span class=hljs-built_in >len</span>)
large_c = entG.subgraph(large_c).copy()
<span class=hljs-comment >#saving original labels and relabeling</span>
old2new = <span class=hljs-built_in >dict</span>(<span class=hljs-built_in >zip</span>(large_c, <span class=hljs-built_in >range</span>(<span class=hljs-number >1</span>, <span class=hljs-built_in >len</span>(large_c.nodes))))
new2old = <span class=hljs-built_in >dict</span>(<span class=hljs-built_in >zip</span>(<span class=hljs-built_in >range</span>(<span class=hljs-number >1</span>, <span class=hljs-built_in >len</span>(large_c.nodes)), large_c))
large_c = nx.relabel_nodes(large_c, mapping=old2new, copy=<span class=hljs-literal >True</span>)</code></pre>
<pre><code class="python hljs">pos = nx.spring_layout(large_c, iterations=<span class=hljs-number >100</span>)

fig, ax = plt.subplots(figsize=(<span class=hljs-number >12</span>, <span class=hljs-number >12</span>))
ax.axis(<span class=hljs-string >&quot;off&quot;</span>)
nx.draw_networkx(large_c,pos=pos, ax=ax,**plot_options)</code></pre>
<p>
<div class=container >

    <img class=center  src="/assets/semnet_largec.svg" width=500  height=500 >

</div>
 now we have a cool looking semantic network, there are lots of type of analysis we can make from a network, like identifying relevant nodes, cliques or communities and other topological features that are non evident or very difficult to identify without constructing the network.</p>
<p>Here we are going to use a community detection algorithm to exemplify its use, from <code>networkx</code> we load the <a href="https://en.wikipedia.org/wiki/Louvain_method">Louvain method</a> which uses <a href="https://en.wikipedia.org/wiki/Modularity_&#40;networks&#41;">modularity</a> as the feature to optimize while finding the communities, this method has the advantage of using the <em>weights</em> of the edges, so it will be more likely for nodes with a strong edge to be in the same community, </p>
<pre><code class="python hljs"><span class=hljs-keyword >from</span> networkx.algorithms.community <span class=hljs-keyword >import</span> louvain_communities
<span class=hljs-comment >#finding communities</span>
parts = louvain_communities(large_c)</code></pre>
<p>now we are going to assign some randomly chosen colors to each of the communities</p>
<pre><code class="python hljs"><span class=hljs-keyword >import</span> matplotlib
<span class=hljs-comment >#getting random colors one for each comunity</span>
col_list = <span class=hljs-built_in >list</span>(matplotlib.colors.cnames.keys())
ncolors = np.random.choice(col_list, <span class=hljs-built_in >len</span>(parts), replace=<span class=hljs-literal >False</span>)
<span class=hljs-comment >#assigning the colors</span>
colors = [<span class=hljs-string >&quot;&quot;</span> <span class=hljs-keyword >for</span> x <span class=hljs-keyword >in</span> <span class=hljs-built_in >range</span>(large_c.number_of_nodes())]
<span class=hljs-keyword >for</span> i,com <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(parts):
    <span class=hljs-keyword >for</span> node <span class=hljs-keyword >in</span> <span class=hljs-built_in >list</span>(com):
        colors[node-<span class=hljs-number >1</span>] = ncolors[i]</code></pre>
<p>and plot the resulting graph</p>
<pre><code class="python hljs">fig, ax = plt.subplots(figsize=(<span class=hljs-number >12</span>, <span class=hljs-number >12</span>))

nx.draw_networkx(large_c, pos=pos,
    node_size=<span class=hljs-number >15</span>,with_labels=<span class=hljs-literal >False</span>, 
    width=<span class=hljs-number >0.5</span>, node_color=colors,
)
ax.axis(<span class=hljs-string >&quot;off&quot;</span>)
fig.set_facecolor(<span class=hljs-string >&#x27;grey&#x27;</span>)</code></pre>

<div class=container >

    <img class=center  src="/assets/semnet_partition.svg" width=500  height=500 >

</div>

<p>we inspect the communities, show how many nodes each of them has</p>
<pre><code class="python hljs"><span class=hljs-keyword >for</span> nc, m <span class=hljs-keyword >in</span> <span class=hljs-built_in >enumerate</span>(parts):
    <span class=hljs-built_in >print</span>(<span class=hljs-string >f&#x27;Component <span class=hljs-subst >{nc}</span> has <span class=hljs-subst >{<span class=hljs-built_in >len</span>(m)}</span> nodes&#x27;</span>)</code></pre>
<pre><code class="plaintext hljs">Component 0 has 2 nodes
Component 1 has 178 nodes
Component 2 has 159 nodes
Component 3 has 8 nodes
Component 4 has 203 nodes
Component 5 has 58 nodes
Component 6 has 22 nodes
Component 7 has 82 nodes
Component 8 has 79 nodes
Component 9 has 65 nodes
Component 10 has 4 nodes
Component 11 has 7 nodes
Component 12 has 23 nodes
Component 13 has 76 nodes
Component 14 has 15 nodes
Component 15 has 9 nodes
Component 16 has 5 nodes
Component 17 has 12 nodes
Component 18 has 8 nodes
Component 19 has 8 nodes
Component 20 has 75 nodes
Component 21 has 9 nodes
Component 22 has 146 nodes
Component 23 has 32 nodes
Component 24 has 54 nodes</code></pre>
<p>to have any idea of what this communities represent we can inspect some of them, it looks like there are at least 3 big communities with more than 100 nodes that probably won&#39;t have easily interpretable information so we are going to expect one of the small ones, for example the 14th </p>
<pre><code class="python hljs">[tag2word[new2old[n]] <span class=hljs-keyword >for</span> n <span class=hljs-keyword >in</span> parts[<span class=hljs-number >14</span>]]</code></pre>
<pre><code class="plaintext hljs">[&#x27;All-Star&#x27;,
 &#x27;MVP&#x27;,
 &#x27;Steve Nash&#x27;,
 &#x27;Warriors&#x27;,
 &#x27;Jordan&#x27;,
 &quot;LeBron James&#x27;&quot;,
 &#x27;Looney Tune-acy&#x27;,
 &#x27;Michael Jordan&#x27;,
 &#x27;Space Jam: A New Legacy&#x27;,
 &#x27;Brooklyn Nets&#x27;,
 &#x27;NBA&#x27;,
 &#x27;Kyrie Irving&#x27;,
 &#x27;Adam Silver&#x27;,
 &#x27;the New Orleans Pelicans&#x27;,
 &#x27;African-American&#x27;]</code></pre>
<p>in this particular case it looks like these nodes are related to each other through <em>basketball</em>, they might be not the only nodes that are related to basketball but they definitely share more between each other than the rest of the basketball related nodes according to the community detection analysis.</p>
<p>If you liked this example don&#39;t forget to take a look at the <a href="https://github.com/spiralizing/WebsiteNotebooks/blob/main/Python/SemanticGraph.ipynb">notebook here</a>.</p>
<div class=page-foot >
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Alfredo Gonz√°lez-Espinoza. Last modified: April 02, 2024.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div>
</div>
      </div> 
  </div> 
  <script src="/libs/pure/ui.min.js"></script>
  
      



  
  
      <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>